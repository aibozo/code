# M7 — Research Orchestration & Hierarchical Agents

Objective
Design and implement a robust research pipeline that fans out lightweight subagents for targeted evidence gathering, then synthesizes their results through a single, high‑quality agent. The pipeline must be deterministic, budget‑aware, observable in the main TUI, and integrate cleanly with existing memory and harness gates.

Scope
- Hierarchical orchestration: leaf minis (e.g., `gpt‑5‑mini`) → single synthesizer (`gpt‑5`) → summary artifact.
- Connectors: ArXiv (MVP), file/web adapters; deterministic caching for offline repeatability.
- Retrieval posture: rate‑limited, bounded pages, stable ranking; dedup and clustering.
- Memory integration: ingest citations + notes + summary into the graph; add edges Episode—(cites)→ResearchSource.
- Observability: live agent status in TUI (Ctrl+A); footer counts; reports/episodes linking.
- Budgets: token/time/concurrency caps; per‑stage and global; fail‑closed under watchdog.
- Provider pacing: linearize `gpt‑5` synthesizer calls (OAuth) with ≥2s spacing; mini‑agent queue enforces ≥0.5s spacing between `gpt‑5‑mini` calls.
- Policy: respect sandbox profile; redact PII; record provenance and tool use.

Acceptance
- End‑to‑end: topic → K leaf notes → 1 synthesizer → `research.md` + citations with stable output on replay (modulo provider nondeterminism).
- Caps enforced: at most 5 minis globally, 1 synthesizer at a time; requests rate‑limited.
- ArXiv MVP connector produces stable, deduped top‑N items; robust to transient failures via retries/backoff.
- TUI shows progress (Ctrl+A), totals, and quick navigation to reports/episodes.

Design overview
- Fan‑out: spawn up to K mini subagents, each assigned a bounded slice of the search space (query windowing, pagination shard, or topic shard). Each mini returns structured notes (bullet points, citation list).
- Fan‑in: pass a curated list of mini notes to a single `gpt‑5` synthesizer with high reasoning; produce an executive summary with prioritized citations.
  - Curation policy: include (per source) abstract (trimmed), contribution one‑liner, and 3–5 methodology bullets. Preserve salient phrasing; avoid aggressive paraphrasing before synthesis.
  - Budgeting into the synthesizer: cap per‑source note at B tokens (e.g., 250–300) and overall fan‑in size at M sources (e.g., ≤10). Prefer top‑ranked sources; drop long tail with a brief omitted list for provenance.
- Concurrency & budgets:
  - Hard caps (code): `gpt‑5` ≤ 1; `gpt‑5‑mini` ≤ 5.
  - Budget plan: K minis (≤ 5), per‑mini token ceiling; synthesizer cap; global watchdog.
  - Queue scheduler starts pending minis when capacity frees; synthesizer waits until minis complete or timeout.
  - Rate limiting: serialize synthesizer calls with ≥2s delay between requests; mini queue emits requests ≥0.5s apart (per process).
- Connectors:
  - ArXiv: simple API (or static HTML fetch) adapter; per‑query determinism; RFC‑8259 JSON cache to `harness/cache/research` keyed by query+filters.
  - Normalization fields: `url`, `title`, `year`, `authors`, `summary`, `score`.
- Ranking & dedup:
  - Primary: arXiv API score or recency; Secondary: cosine similarity distance to topic embeddings; Dedup by URL/domain hash.
  - Compact top‑N=10; minis receive disjoint shards (round‑robin or topic‑clustered).

Data model & memory
- Graph nodes: `ResearchSource(url, title, year, notes)`; edges `Episode—(cites)→ResearchSource`.
- Episode artifacts: `research.md` (synthesis), `sources.json` (normalized citations), `notes-mini-*.md`.
- Ingestion: best‑effort after synthesis; idempotent via `url_hash` keys.

TUI & observability
- Footer: “agents X running” summary; token usage as usual.
- Ctrl+A: Agent Status view with per‑agent: model, elapsed, worktree/branch, errors, last progress lines; quick keys (reports/trends/episodes).
- Reports: daily summaries show deltas; episode summaries include research synopsis and counts.

Error handling & policy
- Retries with exponential backoff for connectors; cache on success; skip on repeated failure and record.
- Redact sensitive content; record tool provenance; respect sandbox policy and approvals.
- Fail‑closed when budgets exceeded; partial results still synthesized with clear disclaimers.

Testing plan
- Connector golden tests (arXiv): normalization, ranking, dedup stability.
- Orchestration unit tests: sharding logic, queue scheduling under caps.
- End‑to‑end dry run: topic → cached sources → fake mini outputs → synthesizer summary; stable artifacts written and ingested.

Out of scope (M7+)
- Additional connectors (Crossref, Semantic Scholar), full web crawling, advanced reranking, and RAG‑like summarization.
- UI filters for per‑citation drill‑down beyond MVP.
